{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8583930,"sourceType":"datasetVersion","datasetId":5133792}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n\nsys.path.insert(0,'/kaggle/input/adain-implementation-with-images/pytorch-AdaIN-master')","metadata":{"execution":{"iopub.status.busy":"2024-06-11T10:19:42.021392Z","iopub.execute_input":"2024-06-11T10:19:42.021758Z","iopub.status.idle":"2024-06-11T10:19:42.028663Z","shell.execute_reply.started":"2024-06-11T10:19:42.021728Z","shell.execute_reply":"2024-06-11T10:19:42.027745Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.utils.data as data\nfrom PIL import Image, ImageFile\nfrom tensorboardX import SummaryWriter\nfrom torchvision import transforms\nfrom tqdm import tqdm\n\nimport net\nfrom sampler import InfiniteSamplerWrapper\n\ncudnn.benchmark = True\nImage.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError\n# Disable OSError: image file is truncated\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n\ndef train_transform():\n    transform_list = [\n        transforms.Resize(size=(512, 512)),\n        transforms.RandomCrop(256),\n        transforms.ToTensor()\n    ]\n    return transforms.Compose(transform_list)\n\n\nclass FlatFolderDataset(data.Dataset):\n    def __init__(self, root, transform):\n        super(FlatFolderDataset, self).__init__()\n        self.root = root\n        self.paths = list(Path(self.root).glob('*'))\n        self.transform = transform\n\n    def __getitem__(self, index):\n        path = self.paths[index]\n        img = Image.open(str(path)).convert('RGB')\n        img = self.transform(img)\n        return img\n\n    def __len__(self):\n        return len(self.paths)\n\n    def name(self):\n        return 'FlatFolderDataset'\n\n# training options\nlr=1e-4\nlr_decay = 5e-5\nbatch_size=8\nstyle_weight=10.0\ncontent_weight=1.0\nn_threads=16\nsave_model_interval = 5000\nmax_iter = 16000\n\ndef adjust_learning_rate(lr,optimizer, iteration_count):\n    \"\"\"Imitating the original implementation\"\"\"\n    lr = lr / (1.0 + lr_decay * iteration_count)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\ndevice = torch.device('cuda')\nsave_dir = Path('./experiments')\nsave_dir.mkdir(exist_ok=True, parents=True)\nlog_dir = Path('./logs')\nlog_dir.mkdir(exist_ok=True, parents=True)\nwriter = SummaryWriter(log_dir=str(log_dir))\n\ndecoder = net.decoder\nvgg = net.vgg\n\nvgg.load_state_dict(torch.load('/kaggle/input/adain-implementation-with-images/pytorch-AdaIN-master/models/vgg_normalised.pth'))\nvgg = nn.Sequential(*list(vgg.children())[:31])\nnetwork = net.Net(vgg, decoder)\nnetwork.train()\nnetwork.to(device)\n\ncontent_tf = train_transform()\nstyle_tf = train_transform()\n\ncontent_dataset = FlatFolderDataset('/kaggle/input/adain-implementation-with-images/pytorch-AdaIN-master/input/content', content_tf)\nstyle_dataset = FlatFolderDataset('/kaggle/input/adain-implementation-with-images/pytorch-AdaIN-master/input/style', style_tf)\n\ncontent_iter = iter(data.DataLoader(\n    content_dataset, batch_size=batch_size,\n    sampler=InfiniteSamplerWrapper(content_dataset),\n    num_workers=n_threads))\nstyle_iter = iter(data.DataLoader(\n    style_dataset, batch_size=batch_size,\n    sampler=InfiniteSamplerWrapper(style_dataset),\n    num_workers=n_threads))\n\noptimizer = torch.optim.AdamW(network.decoder.parameters(), lr=lr)\n\nfor i in tqdm(range(max_iter)):\n    adjust_learning_rate(lr,optimizer, iteration_count=i)\n    content_images = next(content_iter).to(device)\n    style_images = next(style_iter).to(device)\n    loss_c, loss_s = network(content_images, style_images)\n    loss_c = content_weight * loss_c\n    loss_s = style_weight * loss_s\n    loss = loss_c + loss_s\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    writer.add_scalar('loss_content', loss_c.item(), i + 1)\n    writer.add_scalar('loss_style', loss_s.item(), i + 1)\n\n    if (i + 1) % save_model_interval == 0 or (i + 1) == max_iter:\n        state_dict = net.decoder.state_dict()\n        for key in state_dict.keys():\n            state_dict[key] = state_dict[key].to(torch.device('cpu'))\n        torch.save(state_dict, save_dir /\n                   'decoder_iter_{:d}.pth.tar'.format(i + 1))\nwriter.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-11T10:19:42.031326Z","iopub.execute_input":"2024-06-11T10:19:42.031610Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n 89%|████████▉ | 14245/16000 [1:40:00<12:20,  2.37it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}